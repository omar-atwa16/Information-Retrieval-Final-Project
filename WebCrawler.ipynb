{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrxAALHQD+fthdVe7qDeHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omar-atwa16/Information-Retrieval-Final-Project/blob/main/WebCrawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S31NkYIM4G6x",
        "outputId": "011f4846-9b8e-48c4-fb1f-0bb5664432d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from collections import deque, defaultdict\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from flask import Flask, request, jsonify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visted = set()\n",
        "pages = {}\n",
        "invertedIdx = defaultdict(set)\n",
        "\n",
        "lastAccess = {}\n",
        "politenessDelay = 1.5\n",
        "\n",
        "stopWords = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "KX9yG7QLKg5h"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait_for_politeness(url: str) -> None:\n",
        "  host = urlparse(url).netloc\n",
        "  now = time.time()\n",
        "  last = lastAccess.get(host, 0)\n",
        "  wait = politenessDelay - (now - last)\n",
        "  if wait > 0:\n",
        "    time.sleep(wait)\n",
        "  lastAccess[host] = time.time()"
      ],
      "metadata": {
        "id": "bkKMqFQuK0Nw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch(url: str):\n",
        "  try:\n",
        "    wait_for_politeness(url)\n",
        "    resp = requests.get(url)\n",
        "    status = resp.status_code\n",
        "    contentType = resp.headers.get(\"Content-Type\", \"\")\n",
        "    if \"text/html\" in contentType:\n",
        "      return status, resp.text\n",
        "    else:\n",
        "      return status, \"\"\n",
        "  except requests.exceptions.RequestException:\n",
        "    return None, \"\""
      ],
      "metadata": {
        "id": "qnKfZdLrLRJj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_links_and_text (base_url: str, html: str):\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "  outLinks = set()\n",
        "  for a in soup.find_all(\"a\", href=True):\n",
        "    href = a[\"href\"]\n",
        "    absURL = urljoin(base_url, href)\n",
        "    parsed = urlparse(absURL)\n",
        "\n",
        "    if parsed.scheme in (\"http\", \"https\"):\n",
        "      normalized = parsed._replace(fragment=\"\").geturl()\n",
        "      outLinks.add(normalized)\n",
        "\n",
        "  text = soup.get_text(separator=\" \")\n",
        "  return list(outLinks), text"
      ],
      "metadata": {
        "id": "TAcqpNXcMAFR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text: str):\n",
        "  tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
        "  return [t for t in tokens if t not in stopWords]"
      ],
      "metadata": {
        "id": "loQJAXLGM_nN"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_page(url: str, text: str):\n",
        "  for term in tokenize(text):\n",
        "    invertedIdx[term].add(url)"
      ],
      "metadata": {
        "id": "z9kCMv7JNsDC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crawl(start_url: str, maxDepth: int, maxPages: int =50):\n",
        "  frontier = deque()\n",
        "  frontier.append((start_url, 0))\n",
        "  crawled = []\n",
        "  while frontier and len(crawled) < maxPages:\n",
        "    url, depth = frontier.popleft()\n",
        "\n",
        "    if url in visted or depth > maxDepth:\n",
        "      continue\n",
        "\n",
        "    visted.add(url)\n",
        "    status, html = fetch(url)\n",
        "\n",
        "    if status is None:\n",
        "      pages[url] = {\"status\": None, \"outlinks\": []}\n",
        "      continue\n",
        "\n",
        "    if html:\n",
        "      outlinks, text = extract_links_and_text(url, html)\n",
        "      pages[url] = {\"status\": status, \"outlinks\": outlinks}\n",
        "      index_page(url, text)\n",
        "    else:\n",
        "      outlinks = []\n",
        "      pages[url] = {\"status\": status, \"outlinks\": outlinks}\n",
        "\n",
        "    crawled.append(url)\n",
        "\n",
        "    if depth < maxDepth:\n",
        "      for link in outlinks:\n",
        "        if link not in visted:\n",
        "          frontier.append((link, depth + 1))\n",
        "  return crawled"
      ],
      "metadata": {
        "id": "-Qu90M2bYrHc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)"
      ],
      "metadata": {
        "id": "048r8sSuWKws"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/crawl\")\n",
        "def crawl_endpoint():\n",
        "  url = request.args.get(\"url\")\n",
        "\n",
        "  if not url:\n",
        "    return jsonify({\"error\": \"url parameter is required\"})\n",
        "\n",
        "  try:\n",
        "    depth = int(request.args.get(\"depth\", 1))\n",
        "  except ValueError:\n",
        "    depth = 1\n",
        "\n",
        "  try:\n",
        "    maxPages = int(request.args.get(\"maxPages\", 50))\n",
        "  except ValueError:\n",
        "    maxPages = 50\n",
        "\n",
        "\n",
        "  crawledUrls = crawl(url, maxDepth=depth, maxPages=maxPages)\n",
        "\n",
        "  return jsonify({\n",
        "        \"start_url\": url,\n",
        "        \"depth\": depth,\n",
        "        \"max_pages\": maxPages,\n",
        "        \"crawled_count\": len(crawledUrls),\n",
        "        \"crawled_urls\": crawledUrls,\n",
        "    })"
      ],
      "metadata": {
        "id": "4_3WtPVnU1tn"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/index\")\n",
        "def index_endpoint():\n",
        "  term = request.args.get(\"term\", \"\").lower().strip()\n",
        "\n",
        "  if not term:\n",
        "    return jsonify({\"error\": \"term parameter is required\"}), 400\n",
        "\n",
        "  urls = sorted(invertedIdx.get(term, []))\n",
        "  return jsonify({\n",
        "      \"term\": term,\n",
        "      \"count\": len(urls),\n",
        "      \"urls\": urls,\n",
        "  })"
      ],
      "metadata": {
        "id": "s7bf27eNWIs-"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/pages\")\n",
        "def pages_endpoint():\n",
        "  data = []\n",
        "  for url, meta in pages.items():\n",
        "    data.append({\n",
        "        \"url\": url,\n",
        "        \"status\": meta[\"status\"],\n",
        "        \"outlinks\": meta[\"outlinks\"],\n",
        "    })\n",
        "  return jsonify({\n",
        "      \"pages\": data,\n",
        "      \"count\": len(data)\n",
        "  })"
      ],
      "metadata": {
        "id": "BKyAlUbUWlX2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  app.run(debug=True, use_reloader=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCtdn3oSW_iG",
        "outputId": "131e4516-6e66-4fbc-8e78-b0429467bb68"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "http://127.0.0.1:5000/crawl?url=https://pubmed.ncbi.nlm.nih.gov/&depth=1&maxPages=5\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qRvkQs6fXRIb",
        "outputId": "e458520a-c1d9-45fa-b2ce-0e8d658e6c52"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhttp://127.0.0.1:5000/crawl?url=https://pubmed.ncbi.nlm.nih.gov/&depth=1&maxPages=5\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}